# Interval analysis of large tokamak
# 8 uncertain parameters

# Dakota Input File
# Usage:
#   dakota -i ia_lt_8p.in > ia_lt_8p.out

environment
  # Full output data (stdout)
  # output_file "ia_lt_8p.out"
  # Error file (stderr)
  # error_file "ia_lt_8p_err.log"
  # Final results (e.g. best parameters, summary data)
  # results_output
    # Final results not in text output or h5 output!
    # Use stdout output file instead: only thing that contains results!
    # text 
    # hdf5
    # results_output_file "results"
  # Outputs evaluations only, not final results
  # tabular_data
    # tabular_data_file "ia_lt_8p.dat"

# IA study
method
    global_interval_est ego
    seed = 1234567

variables
  continuous_interval_uncertain = 8
    num_intervals = 8 * 1
    interval_probabilities = 8 * 1.0
    descriptors   "fimp_14"  "triang"  "kappa"  "flhthresh"   "cboot"  "etaech"  "etath"  "etaiso"
    lower_bounds  1.0e-5          0.4    1.8         0.85      0.95       0.3     0.36      0.75
    upper_bounds  1.0e-4          0.6    1.9         1.15      1.05       0.5     0.4       0.95
  # State vars at solution values
  continuous_state = 13
    descriptors = "fdene"  "hfact"  "coreradius"  "fimp_2"  "psepbqarmax"  "peakfactrad"  "feffcd"  "boundl_18"  "pinjalw"  "alstroh"  "sig_tf_wp_max"  "aspect"  "boundu_2"
    initial_state = 1.2  1.1993307161977502  0.7500000000000001  0.1  10.0  3.33  1.0  3.0  200.0  750000000.0  750000000.0  3.0  30.0

interface
  fork
    labeled
    analysis_drivers = 'python process_driver.py lt_sol.template'
    parameters_file = 'params.in'
    results_file    = 'responses.out'
    work_directory 
      named "runs/lt/run"
      directory_tag # Keep run dirs unique: required for parallelism
      link_files = "../run_dir_template/*"
      
      # Debug
      # directory_save # Keep individual run dirs
      # file_save # save Dakota .in and .out files

responses
  response_functions = 1
  descriptors "w"
  no_gradients
  no_hessians
  metadata "w_con_id"